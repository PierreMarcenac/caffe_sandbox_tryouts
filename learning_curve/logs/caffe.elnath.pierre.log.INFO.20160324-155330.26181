Log file created at: 2016/03/24 15:53:30
Running on machine: elnath
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0324 15:53:30.038831 26181 caffe.cpp:185] Using GPUs 0
I0324 15:53:30.042781 26181 caffe.cpp:190] GPU 0: GeForce GTX 580
I0324 15:53:30.193527 26181 solver.cpp:48] Initializing solver from parameters: 
train_net: "prototxt/net_hdf5_train.prototxt"
test_net: "prototxt/net_hdf5_test.prototxt"
test_iter: 100
test_interval: 100
base_lr: 0.01
display: 10
max_iter: 1000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
solver_mode: GPU
device_id: 0
random_seed: 831486
type: "Nesterov"
I0324 15:53:30.193645 26181 solver.cpp:81] Creating training net from train_net file: prototxt/net_hdf5_train.prototxt
I0324 15:53:30.194041 26181 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/mnt/scratch/pierre/caffe_sandbox_tryouts/mnist/mnist_train_hdf5/h5list"
    batch_size: 64
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 50
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 50
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "fc1"
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc1"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0324 15:53:30.194421 26181 layer_factory.hpp:77] Creating layer data
I0324 15:53:30.194444 26181 net.cpp:91] Creating Layer data
I0324 15:53:30.194460 26181 net.cpp:399] data -> data
I0324 15:53:30.194491 26181 net.cpp:399] data -> label
I0324 15:53:30.194514 26181 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/scratch/pierre/caffe_sandbox_tryouts/mnist/mnist_train_hdf5/h5list
I0324 15:53:30.194581 26181 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0324 15:53:30.195955 26181 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0324 15:53:30.354568 26181 net.cpp:141] Setting up data
I0324 15:53:30.354624 26181 net.cpp:148] Top shape: 64 1 28 28 (50176)
I0324 15:53:30.354640 26181 net.cpp:148] Top shape: 64 10 (640)
I0324 15:53:30.354650 26181 net.cpp:156] Memory required for data: 203264
I0324 15:53:30.354665 26181 layer_factory.hpp:77] Creating layer conv1
I0324 15:53:30.354698 26181 net.cpp:91] Creating Layer conv1
I0324 15:53:30.354712 26181 net.cpp:425] conv1 <- data
I0324 15:53:30.354729 26181 net.cpp:399] conv1 -> conv1
I0324 15:53:30.356108 26181 net.cpp:141] Setting up conv1
I0324 15:53:30.356133 26181 net.cpp:148] Top shape: 64 50 24 24 (1843200)
I0324 15:53:30.356143 26181 net.cpp:156] Memory required for data: 7576064
I0324 15:53:30.356168 26181 layer_factory.hpp:77] Creating layer pool1
I0324 15:53:30.356184 26181 net.cpp:91] Creating Layer pool1
I0324 15:53:30.356194 26181 net.cpp:425] pool1 <- conv1
I0324 15:53:30.356207 26181 net.cpp:399] pool1 -> pool1
I0324 15:53:30.356268 26181 net.cpp:141] Setting up pool1
I0324 15:53:30.356288 26181 net.cpp:148] Top shape: 64 50 12 12 (460800)
I0324 15:53:30.356297 26181 net.cpp:156] Memory required for data: 9419264
I0324 15:53:30.356308 26181 layer_factory.hpp:77] Creating layer relu1
I0324 15:53:30.356322 26181 net.cpp:91] Creating Layer relu1
I0324 15:53:30.356331 26181 net.cpp:425] relu1 <- pool1
I0324 15:53:30.356343 26181 net.cpp:386] relu1 -> pool1 (in-place)
I0324 15:53:30.356394 26181 net.cpp:141] Setting up relu1
I0324 15:53:30.356412 26181 net.cpp:148] Top shape: 64 50 12 12 (460800)
I0324 15:53:30.356421 26181 net.cpp:156] Memory required for data: 11262464
I0324 15:53:30.356431 26181 layer_factory.hpp:77] Creating layer conv2
I0324 15:53:30.356447 26181 net.cpp:91] Creating Layer conv2
I0324 15:53:30.356462 26181 net.cpp:425] conv2 <- pool1
I0324 15:53:30.356474 26181 net.cpp:399] conv2 -> conv2
I0324 15:53:30.357692 26181 net.cpp:141] Setting up conv2
I0324 15:53:30.357717 26181 net.cpp:148] Top shape: 64 50 8 8 (204800)
I0324 15:53:30.357727 26181 net.cpp:156] Memory required for data: 12081664
I0324 15:53:30.357743 26181 layer_factory.hpp:77] Creating layer pool2
I0324 15:53:30.357756 26181 net.cpp:91] Creating Layer pool2
I0324 15:53:30.357767 26181 net.cpp:425] pool2 <- conv2
I0324 15:53:30.357779 26181 net.cpp:399] pool2 -> pool2
I0324 15:53:30.357826 26181 net.cpp:141] Setting up pool2
I0324 15:53:30.357843 26181 net.cpp:148] Top shape: 64 50 4 4 (51200)
I0324 15:53:30.357853 26181 net.cpp:156] Memory required for data: 12286464
I0324 15:53:30.357863 26181 layer_factory.hpp:77] Creating layer relu2
I0324 15:53:30.357875 26181 net.cpp:91] Creating Layer relu2
I0324 15:53:30.357885 26181 net.cpp:425] relu2 <- pool2
I0324 15:53:30.357897 26181 net.cpp:386] relu2 -> pool2 (in-place)
I0324 15:53:30.357911 26181 net.cpp:141] Setting up relu2
I0324 15:53:30.357923 26181 net.cpp:148] Top shape: 64 50 4 4 (51200)
I0324 15:53:30.357933 26181 net.cpp:156] Memory required for data: 12491264
I0324 15:53:30.357941 26181 layer_factory.hpp:77] Creating layer fc1
I0324 15:53:30.357959 26181 net.cpp:91] Creating Layer fc1
I0324 15:53:30.357969 26181 net.cpp:425] fc1 <- pool2
I0324 15:53:30.357982 26181 net.cpp:399] fc1 -> fc1
I0324 15:53:30.361699 26181 net.cpp:141] Setting up fc1
I0324 15:53:30.361723 26181 net.cpp:148] Top shape: 64 500 (32000)
I0324 15:53:30.361734 26181 net.cpp:156] Memory required for data: 12619264
I0324 15:53:30.361752 26181 layer_factory.hpp:77] Creating layer score
I0324 15:53:30.361766 26181 net.cpp:91] Creating Layer score
I0324 15:53:30.361778 26181 net.cpp:425] score <- fc1
I0324 15:53:30.361790 26181 net.cpp:399] score -> score
I0324 15:53:30.362473 26181 net.cpp:141] Setting up score
I0324 15:53:30.362495 26181 net.cpp:148] Top shape: 64 10 (640)
I0324 15:53:30.362506 26181 net.cpp:156] Memory required for data: 12621824
I0324 15:53:30.362520 26181 layer_factory.hpp:77] Creating layer loss
I0324 15:53:30.362539 26181 net.cpp:91] Creating Layer loss
I0324 15:53:30.362550 26181 net.cpp:425] loss <- score
I0324 15:53:30.362562 26181 net.cpp:425] loss <- label
I0324 15:53:30.362576 26181 net.cpp:399] loss -> loss
I0324 15:53:30.362633 26181 net.cpp:141] Setting up loss
I0324 15:53:30.362651 26181 net.cpp:148] Top shape: (1)
I0324 15:53:30.362663 26181 net.cpp:151]     with loss weight 1
I0324 15:53:30.362695 26181 net.cpp:156] Memory required for data: 12621828
I0324 15:53:30.362706 26181 net.cpp:217] loss needs backward computation.
I0324 15:53:30.362716 26181 net.cpp:217] score needs backward computation.
I0324 15:53:30.362725 26181 net.cpp:217] fc1 needs backward computation.
I0324 15:53:30.362735 26181 net.cpp:217] relu2 needs backward computation.
I0324 15:53:30.362745 26181 net.cpp:217] pool2 needs backward computation.
I0324 15:53:30.362753 26181 net.cpp:217] conv2 needs backward computation.
I0324 15:53:30.362763 26181 net.cpp:217] relu1 needs backward computation.
I0324 15:53:30.362772 26181 net.cpp:217] pool1 needs backward computation.
I0324 15:53:30.362782 26181 net.cpp:217] conv1 needs backward computation.
I0324 15:53:30.362792 26181 net.cpp:219] data does not need backward computation.
I0324 15:53:30.362809 26181 net.cpp:261] This network produces output loss
I0324 15:53:30.362825 26181 net.cpp:274] Network initialization done.
I0324 15:53:30.363095 26181 solver.cpp:181] Creating test net (#0) specified by test_net file: prototxt/net_hdf5_test.prototxt
I0324 15:53:30.363231 26181 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  hdf5_data_param {
    source: "/mnt/scratch/pierre/caffe_sandbox_tryouts/mnist/mnist_test_hdf5/h5list"
    batch_size: 100
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 50
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 50
    kernel_size: 5
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "pool2"
  top: "pool2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "fc1"
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc1"
  top: "score"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SigmoidCrossEntropyLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0324 15:53:30.363579 26181 layer_factory.hpp:77] Creating layer data
I0324 15:53:30.363598 26181 net.cpp:91] Creating Layer data
I0324 15:53:30.363610 26181 net.cpp:399] data -> data
I0324 15:53:30.363625 26181 net.cpp:399] data -> label
I0324 15:53:30.363639 26181 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /mnt/scratch/pierre/caffe_sandbox_tryouts/mnist/mnist_test_hdf5/h5list
I0324 15:53:30.363674 26181 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0324 15:53:30.389166 26181 net.cpp:141] Setting up data
I0324 15:53:30.389214 26181 net.cpp:148] Top shape: 100 1 28 28 (78400)
I0324 15:53:30.389227 26181 net.cpp:148] Top shape: 100 10 (1000)
I0324 15:53:30.389236 26181 net.cpp:156] Memory required for data: 317600
I0324 15:53:30.389251 26181 layer_factory.hpp:77] Creating layer conv1
I0324 15:53:30.389277 26181 net.cpp:91] Creating Layer conv1
I0324 15:53:30.389289 26181 net.cpp:425] conv1 <- data
I0324 15:53:30.389304 26181 net.cpp:399] conv1 -> conv1
I0324 15:53:30.389595 26181 net.cpp:141] Setting up conv1
I0324 15:53:30.389616 26181 net.cpp:148] Top shape: 100 50 24 24 (2880000)
I0324 15:53:30.389626 26181 net.cpp:156] Memory required for data: 11837600
I0324 15:53:30.389647 26181 layer_factory.hpp:77] Creating layer pool1
I0324 15:53:30.389662 26181 net.cpp:91] Creating Layer pool1
I0324 15:53:30.389672 26181 net.cpp:425] pool1 <- conv1
I0324 15:53:30.389684 26181 net.cpp:399] pool1 -> pool1
I0324 15:53:30.389734 26181 net.cpp:141] Setting up pool1
I0324 15:53:30.389752 26181 net.cpp:148] Top shape: 100 50 12 12 (720000)
I0324 15:53:30.389762 26181 net.cpp:156] Memory required for data: 14717600
I0324 15:53:30.389772 26181 layer_factory.hpp:77] Creating layer relu1
I0324 15:53:30.389785 26181 net.cpp:91] Creating Layer relu1
I0324 15:53:30.389794 26181 net.cpp:425] relu1 <- pool1
I0324 15:53:30.389806 26181 net.cpp:386] relu1 -> pool1 (in-place)
I0324 15:53:30.389819 26181 net.cpp:141] Setting up relu1
I0324 15:53:30.389832 26181 net.cpp:148] Top shape: 100 50 12 12 (720000)
I0324 15:53:30.389840 26181 net.cpp:156] Memory required for data: 17597600
I0324 15:53:30.389850 26181 layer_factory.hpp:77] Creating layer conv2
I0324 15:53:30.389865 26181 net.cpp:91] Creating Layer conv2
I0324 15:53:30.389881 26181 net.cpp:425] conv2 <- pool1
I0324 15:53:30.389894 26181 net.cpp:399] conv2 -> conv2
I0324 15:53:30.390614 26181 net.cpp:141] Setting up conv2
I0324 15:53:30.390636 26181 net.cpp:148] Top shape: 100 50 8 8 (320000)
I0324 15:53:30.390647 26181 net.cpp:156] Memory required for data: 18877600
I0324 15:53:30.390662 26181 layer_factory.hpp:77] Creating layer pool2
I0324 15:53:30.390707 26181 net.cpp:91] Creating Layer pool2
I0324 15:53:30.390717 26181 net.cpp:425] pool2 <- conv2
I0324 15:53:30.390730 26181 net.cpp:399] pool2 -> pool2
I0324 15:53:30.390779 26181 net.cpp:141] Setting up pool2
I0324 15:53:30.390797 26181 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0324 15:53:30.390807 26181 net.cpp:156] Memory required for data: 19197600
I0324 15:53:30.390817 26181 layer_factory.hpp:77] Creating layer relu2
I0324 15:53:30.390830 26181 net.cpp:91] Creating Layer relu2
I0324 15:53:30.390839 26181 net.cpp:425] relu2 <- pool2
I0324 15:53:30.390851 26181 net.cpp:386] relu2 -> pool2 (in-place)
I0324 15:53:30.390864 26181 net.cpp:141] Setting up relu2
I0324 15:53:30.390875 26181 net.cpp:148] Top shape: 100 50 4 4 (80000)
I0324 15:53:30.390885 26181 net.cpp:156] Memory required for data: 19517600
I0324 15:53:30.390895 26181 layer_factory.hpp:77] Creating layer fc1
I0324 15:53:30.390910 26181 net.cpp:91] Creating Layer fc1
I0324 15:53:30.390924 26181 net.cpp:425] fc1 <- pool2
I0324 15:53:30.390938 26181 net.cpp:399] fc1 -> fc1
I0324 15:53:30.394662 26181 net.cpp:141] Setting up fc1
I0324 15:53:30.394686 26181 net.cpp:148] Top shape: 100 500 (50000)
I0324 15:53:30.394696 26181 net.cpp:156] Memory required for data: 19717600
I0324 15:53:30.394713 26181 layer_factory.hpp:77] Creating layer score
I0324 15:53:30.394728 26181 net.cpp:91] Creating Layer score
I0324 15:53:30.394739 26181 net.cpp:425] score <- fc1
I0324 15:53:30.394752 26181 net.cpp:399] score -> score
I0324 15:53:30.394906 26181 net.cpp:141] Setting up score
I0324 15:53:30.394925 26181 net.cpp:148] Top shape: 100 10 (1000)
I0324 15:53:30.394934 26181 net.cpp:156] Memory required for data: 19721600
I0324 15:53:30.394948 26181 layer_factory.hpp:77] Creating layer loss
I0324 15:53:30.394963 26181 net.cpp:91] Creating Layer loss
I0324 15:53:30.394973 26181 net.cpp:425] loss <- score
I0324 15:53:30.394984 26181 net.cpp:425] loss <- label
I0324 15:53:30.394995 26181 net.cpp:399] loss -> loss
I0324 15:53:30.395045 26181 net.cpp:141] Setting up loss
I0324 15:53:30.395062 26181 net.cpp:148] Top shape: (1)
I0324 15:53:30.395078 26181 net.cpp:151]     with loss weight 1
I0324 15:53:30.395102 26181 net.cpp:156] Memory required for data: 19721604
I0324 15:53:30.395112 26181 net.cpp:217] loss needs backward computation.
I0324 15:53:30.395122 26181 net.cpp:217] score needs backward computation.
I0324 15:53:30.395130 26181 net.cpp:217] fc1 needs backward computation.
I0324 15:53:30.395140 26181 net.cpp:217] relu2 needs backward computation.
I0324 15:53:30.395148 26181 net.cpp:217] pool2 needs backward computation.
I0324 15:53:30.395158 26181 net.cpp:217] conv2 needs backward computation.
I0324 15:53:30.395166 26181 net.cpp:217] relu1 needs backward computation.
I0324 15:53:30.395180 26181 net.cpp:217] pool1 needs backward computation.
I0324 15:53:30.395190 26181 net.cpp:217] conv1 needs backward computation.
I0324 15:53:30.395202 26181 net.cpp:219] data does not need backward computation.
I0324 15:53:30.395211 26181 net.cpp:261] This network produces output loss
I0324 15:53:30.395231 26181 net.cpp:274] Network initialization done.
I0324 15:53:30.395272 26181 solver.cpp:60] Solver scaffolding done.
I0324 15:53:30.395601 26181 caffe.cpp:219] Starting Optimization
I0324 15:53:30.395619 26181 solver.cpp:279] Solving 
I0324 15:53:30.395629 26181 solver.cpp:280] Learning Rate Policy: inv
I0324 15:53:30.396368 26181 solver.cpp:337] Iteration 0, Testing net (#0)
I0324 15:53:34.692728 26181 solver.cpp:404]     Test net output #0: loss = 7.31435 (* 1 = 7.31435 loss)
I0324 15:53:34.725633 26181 solver.cpp:228] Iteration 0, loss = 7.29185
I0324 15:53:34.725720 26181 solver.cpp:244]     Train net output #0: loss = 7.29185 (* 1 = 7.29185 loss)
I0324 15:53:34.725759 26181 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0324 15:53:35.125025 26181 solver.cpp:228] Iteration 10, loss = 2.62035
I0324 15:53:35.125105 26181 solver.cpp:244]     Train net output #0: loss = 2.62035 (* 1 = 2.62035 loss)
I0324 15:53:35.125120 26181 sgd_solver.cpp:106] Iteration 10, lr = 0.00999251
I0324 15:53:35.525077 26181 solver.cpp:228] Iteration 20, loss = 1.91238
I0324 15:53:35.525154 26181 solver.cpp:244]     Train net output #0: loss = 1.91238 (* 1 = 1.91238 loss)
I0324 15:53:35.525169 26181 sgd_solver.cpp:106] Iteration 20, lr = 0.00998503
I0324 15:53:35.924437 26181 solver.cpp:228] Iteration 30, loss = 0.830812
I0324 15:53:35.924513 26181 solver.cpp:244]     Train net output #0: loss = 0.830812 (* 1 = 0.830812 loss)
I0324 15:53:35.924530 26181 sgd_solver.cpp:106] Iteration 30, lr = 0.00997756
I0324 15:53:36.323797 26181 solver.cpp:228] Iteration 40, loss = 0.625363
I0324 15:53:36.323907 26181 solver.cpp:244]     Train net output #0: loss = 0.625363 (* 1 = 0.625363 loss)
I0324 15:53:36.323925 26181 sgd_solver.cpp:106] Iteration 40, lr = 0.0099701
I0324 15:53:36.722790 26181 solver.cpp:228] Iteration 50, loss = 0.595844
I0324 15:53:36.722868 26181 solver.cpp:244]     Train net output #0: loss = 0.595844 (* 1 = 0.595844 loss)
I0324 15:53:36.722887 26181 sgd_solver.cpp:106] Iteration 50, lr = 0.00996266
I0324 15:53:37.121973 26181 solver.cpp:228] Iteration 60, loss = 0.36156
I0324 15:53:37.122045 26181 solver.cpp:244]     Train net output #0: loss = 0.36156 (* 1 = 0.36156 loss)
I0324 15:53:37.122059 26181 sgd_solver.cpp:106] Iteration 60, lr = 0.00995523
I0324 15:53:37.521011 26181 solver.cpp:228] Iteration 70, loss = 0.52085
I0324 15:53:37.521086 26181 solver.cpp:244]     Train net output #0: loss = 0.52085 (* 1 = 0.52085 loss)
I0324 15:53:37.521103 26181 sgd_solver.cpp:106] Iteration 70, lr = 0.00994782
I0324 15:53:37.920302 26181 solver.cpp:228] Iteration 80, loss = 0.823596
I0324 15:53:37.920377 26181 solver.cpp:244]     Train net output #0: loss = 0.823596 (* 1 = 0.823596 loss)
I0324 15:53:37.920390 26181 sgd_solver.cpp:106] Iteration 80, lr = 0.00994042
I0324 15:53:38.319851 26181 solver.cpp:228] Iteration 90, loss = 0.475457
I0324 15:53:38.319928 26181 solver.cpp:244]     Train net output #0: loss = 0.475457 (* 1 = 0.475457 loss)
I0324 15:53:38.319946 26181 sgd_solver.cpp:106] Iteration 90, lr = 0.00993303
I0324 15:53:38.679239 26181 solver.cpp:337] Iteration 100, Testing net (#0)
I0324 15:53:42.987684 26181 solver.cpp:404]     Test net output #0: loss = 0.491015 (* 1 = 0.491015 loss)
I0324 15:53:43.017815 26181 solver.cpp:228] Iteration 100, loss = 0.311766
I0324 15:53:43.017843 26181 solver.cpp:244]     Train net output #0: loss = 0.311766 (* 1 = 0.311766 loss)
I0324 15:53:43.017860 26181 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0324 15:53:43.416774 26181 solver.cpp:228] Iteration 110, loss = 0.335592
I0324 15:53:43.416800 26181 solver.cpp:244]     Train net output #0: loss = 0.335592 (* 1 = 0.335592 loss)
I0324 15:53:43.416813 26181 sgd_solver.cpp:106] Iteration 110, lr = 0.00991829
I0324 15:53:43.815768 26181 solver.cpp:228] Iteration 120, loss = 0.438676
I0324 15:53:43.815794 26181 solver.cpp:244]     Train net output #0: loss = 0.438676 (* 1 = 0.438676 loss)
I0324 15:53:43.815806 26181 sgd_solver.cpp:106] Iteration 120, lr = 0.00991093
I0324 15:53:44.214786 26181 solver.cpp:228] Iteration 130, loss = 0.249971
I0324 15:53:44.214821 26181 solver.cpp:244]     Train net output #0: loss = 0.249971 (* 1 = 0.249971 loss)
I0324 15:53:44.214838 26181 sgd_solver.cpp:106] Iteration 130, lr = 0.0099036
I0324 15:53:44.613734 26181 solver.cpp:228] Iteration 140, loss = 0.523535
I0324 15:53:44.613762 26181 solver.cpp:244]     Train net output #0: loss = 0.523535 (* 1 = 0.523535 loss)
I0324 15:53:44.613775 26181 sgd_solver.cpp:106] Iteration 140, lr = 0.00989627
I0324 15:53:45.012706 26181 solver.cpp:228] Iteration 150, loss = 0.385028
I0324 15:53:45.012732 26181 solver.cpp:244]     Train net output #0: loss = 0.385027 (* 1 = 0.385027 loss)
I0324 15:53:45.012745 26181 sgd_solver.cpp:106] Iteration 150, lr = 0.00988896
I0324 15:53:45.411731 26181 solver.cpp:228] Iteration 160, loss = 0.44354
I0324 15:53:45.411757 26181 solver.cpp:244]     Train net output #0: loss = 0.44354 (* 1 = 0.44354 loss)
I0324 15:53:45.411770 26181 sgd_solver.cpp:106] Iteration 160, lr = 0.00988166
I0324 15:53:45.810714 26181 solver.cpp:228] Iteration 170, loss = 0.383264
I0324 15:53:45.810742 26181 solver.cpp:244]     Train net output #0: loss = 0.383264 (* 1 = 0.383264 loss)
I0324 15:53:45.810755 26181 sgd_solver.cpp:106] Iteration 170, lr = 0.00987437
I0324 15:53:46.209693 26181 solver.cpp:228] Iteration 180, loss = 0.630658
I0324 15:53:46.209722 26181 solver.cpp:244]     Train net output #0: loss = 0.630658 (* 1 = 0.630658 loss)
I0324 15:53:46.209734 26181 sgd_solver.cpp:106] Iteration 180, lr = 0.00986709
I0324 15:53:46.608724 26181 solver.cpp:228] Iteration 190, loss = 0.276227
I0324 15:53:46.608750 26181 solver.cpp:244]     Train net output #0: loss = 0.276227 (* 1 = 0.276227 loss)
I0324 15:53:46.608763 26181 sgd_solver.cpp:106] Iteration 190, lr = 0.00985983
I0324 15:53:46.968209 26181 solver.cpp:337] Iteration 200, Testing net (#0)
I0324 15:53:51.270460 26181 solver.cpp:404]     Test net output #0: loss = 0.327946 (* 1 = 0.327946 loss)
I0324 15:53:51.300550 26181 solver.cpp:228] Iteration 200, loss = 0.249133
I0324 15:53:51.300577 26181 solver.cpp:244]     Train net output #0: loss = 0.249133 (* 1 = 0.249133 loss)
I0324 15:53:51.300593 26181 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0324 15:53:51.699357 26181 solver.cpp:228] Iteration 210, loss = 0.280803
I0324 15:53:51.699390 26181 solver.cpp:244]     Train net output #0: loss = 0.280802 (* 1 = 0.280802 loss)
I0324 15:53:51.699404 26181 sgd_solver.cpp:106] Iteration 210, lr = 0.00984534
I0324 15:53:52.098084 26181 solver.cpp:228] Iteration 220, loss = 0.268094
I0324 15:53:52.098112 26181 solver.cpp:244]     Train net output #0: loss = 0.268094 (* 1 = 0.268094 loss)
I0324 15:53:52.098124 26181 sgd_solver.cpp:106] Iteration 220, lr = 0.00983811
I0324 15:53:52.496915 26181 solver.cpp:228] Iteration 230, loss = 0.619459
I0324 15:53:52.496943 26181 solver.cpp:244]     Train net output #0: loss = 0.619459 (* 1 = 0.619459 loss)
I0324 15:53:52.496955 26181 sgd_solver.cpp:106] Iteration 230, lr = 0.0098309
I0324 15:53:52.895717 26181 solver.cpp:228] Iteration 240, loss = 0.389726
I0324 15:53:52.895745 26181 solver.cpp:244]     Train net output #0: loss = 0.389726 (* 1 = 0.389726 loss)
I0324 15:53:52.895758 26181 sgd_solver.cpp:106] Iteration 240, lr = 0.0098237
I0324 15:53:53.294464 26181 solver.cpp:228] Iteration 250, loss = 0.482943
I0324 15:53:53.294492 26181 solver.cpp:244]     Train net output #0: loss = 0.482942 (* 1 = 0.482942 loss)
I0324 15:53:53.294505 26181 sgd_solver.cpp:106] Iteration 250, lr = 0.00981651
I0324 15:53:53.693274 26181 solver.cpp:228] Iteration 260, loss = 0.330533
I0324 15:53:53.693300 26181 solver.cpp:244]     Train net output #0: loss = 0.330532 (* 1 = 0.330532 loss)
I0324 15:53:53.693312 26181 sgd_solver.cpp:106] Iteration 260, lr = 0.00980933
I0324 15:53:54.092105 26181 solver.cpp:228] Iteration 270, loss = 0.164771
I0324 15:53:54.092133 26181 solver.cpp:244]     Train net output #0: loss = 0.164771 (* 1 = 0.164771 loss)
I0324 15:53:54.092144 26181 sgd_solver.cpp:106] Iteration 270, lr = 0.00980217
I0324 15:53:54.490809 26181 solver.cpp:228] Iteration 280, loss = 0.208049
I0324 15:53:54.490838 26181 solver.cpp:244]     Train net output #0: loss = 0.208049 (* 1 = 0.208049 loss)
I0324 15:53:54.490850 26181 sgd_solver.cpp:106] Iteration 280, lr = 0.00979502
I0324 15:53:54.889608 26181 solver.cpp:228] Iteration 290, loss = 0.316061
I0324 15:53:54.889637 26181 solver.cpp:244]     Train net output #0: loss = 0.316061 (* 1 = 0.316061 loss)
I0324 15:53:54.889650 26181 sgd_solver.cpp:106] Iteration 290, lr = 0.00978788
I0324 15:53:55.248636 26181 solver.cpp:337] Iteration 300, Testing net (#0)
I0324 15:53:59.545653 26181 solver.cpp:404]     Test net output #0: loss = 0.234749 (* 1 = 0.234749 loss)
I0324 15:53:59.575788 26181 solver.cpp:228] Iteration 300, loss = 0.387093
I0324 15:53:59.575814 26181 solver.cpp:244]     Train net output #0: loss = 0.387093 (* 1 = 0.387093 loss)
I0324 15:53:59.575831 26181 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0324 15:53:59.974427 26181 solver.cpp:228] Iteration 310, loss = 0.157228
I0324 15:53:59.974488 26181 solver.cpp:244]     Train net output #0: loss = 0.157228 (* 1 = 0.157228 loss)
I0324 15:53:59.974503 26181 sgd_solver.cpp:106] Iteration 310, lr = 0.00977363
I0324 15:54:00.373203 26181 solver.cpp:228] Iteration 320, loss = 0.110793
I0324 15:54:00.373831 26181 solver.cpp:244]     Train net output #0: loss = 0.110793 (* 1 = 0.110793 loss)
I0324 15:54:00.373857 26181 sgd_solver.cpp:106] Iteration 320, lr = 0.00976653
I0324 15:54:00.772367 26181 solver.cpp:228] Iteration 330, loss = 0.289284
I0324 15:54:00.772397 26181 solver.cpp:244]     Train net output #0: loss = 0.289284 (* 1 = 0.289284 loss)
I0324 15:54:00.772409 26181 sgd_solver.cpp:106] Iteration 330, lr = 0.00975944
I0324 15:54:01.171044 26181 solver.cpp:228] Iteration 340, loss = 0.0737725
I0324 15:54:01.171108 26181 solver.cpp:244]     Train net output #0: loss = 0.0737723 (* 1 = 0.0737723 loss)
I0324 15:54:01.171120 26181 sgd_solver.cpp:106] Iteration 340, lr = 0.00975236
I0324 15:54:01.569830 26181 solver.cpp:228] Iteration 350, loss = 0.156083
I0324 15:54:01.569859 26181 solver.cpp:244]     Train net output #0: loss = 0.156082 (* 1 = 0.156082 loss)
I0324 15:54:01.569871 26181 sgd_solver.cpp:106] Iteration 350, lr = 0.00974529
I0324 15:54:01.968598 26181 solver.cpp:228] Iteration 360, loss = 0.274266
I0324 15:54:01.968626 26181 solver.cpp:244]     Train net output #0: loss = 0.274265 (* 1 = 0.274265 loss)
I0324 15:54:01.968637 26181 sgd_solver.cpp:106] Iteration 360, lr = 0.00973823
I0324 15:54:02.367436 26181 solver.cpp:228] Iteration 370, loss = 0.325379
I0324 15:54:02.367462 26181 solver.cpp:244]     Train net output #0: loss = 0.325378 (* 1 = 0.325378 loss)
I0324 15:54:02.367475 26181 sgd_solver.cpp:106] Iteration 370, lr = 0.00973119
I0324 15:54:02.766162 26181 solver.cpp:228] Iteration 380, loss = 0.096893
I0324 15:54:02.766190 26181 solver.cpp:244]     Train net output #0: loss = 0.0968929 (* 1 = 0.0968929 loss)
I0324 15:54:02.766202 26181 sgd_solver.cpp:106] Iteration 380, lr = 0.00972416
I0324 15:54:03.164921 26181 solver.cpp:228] Iteration 390, loss = 0.147774
I0324 15:54:03.164947 26181 solver.cpp:244]     Train net output #0: loss = 0.147774 (* 1 = 0.147774 loss)
I0324 15:54:03.164960 26181 sgd_solver.cpp:106] Iteration 390, lr = 0.00971714
I0324 15:54:03.523918 26181 solver.cpp:337] Iteration 400, Testing net (#0)
I0324 15:54:07.819983 26181 solver.cpp:404]     Test net output #0: loss = 0.229991 (* 1 = 0.229991 loss)
I0324 15:54:07.850005 26181 solver.cpp:228] Iteration 400, loss = 0.190416
I0324 15:54:07.850033 26181 solver.cpp:244]     Train net output #0: loss = 0.190416 (* 1 = 0.190416 loss)
I0324 15:54:07.850049 26181 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0324 15:54:08.248749 26181 solver.cpp:228] Iteration 410, loss = 0.157256
I0324 15:54:08.248775 26181 solver.cpp:244]     Train net output #0: loss = 0.157256 (* 1 = 0.157256 loss)
I0324 15:54:08.248787 26181 sgd_solver.cpp:106] Iteration 410, lr = 0.00970313
I0324 15:54:08.647492 26181 solver.cpp:228] Iteration 420, loss = 0.23449
I0324 15:54:08.647519 26181 solver.cpp:244]     Train net output #0: loss = 0.234489 (* 1 = 0.234489 loss)
I0324 15:54:08.647531 26181 sgd_solver.cpp:106] Iteration 420, lr = 0.00969615
I0324 15:54:09.046221 26181 solver.cpp:228] Iteration 430, loss = 0.32515
I0324 15:54:09.046249 26181 solver.cpp:244]     Train net output #0: loss = 0.32515 (* 1 = 0.32515 loss)
I0324 15:54:09.046262 26181 sgd_solver.cpp:106] Iteration 430, lr = 0.00968917
I0324 15:54:09.444986 26181 solver.cpp:228] Iteration 440, loss = 0.103157
I0324 15:54:09.445014 26181 solver.cpp:244]     Train net output #0: loss = 0.103157 (* 1 = 0.103157 loss)
I0324 15:54:09.445026 26181 sgd_solver.cpp:106] Iteration 440, lr = 0.00968221
I0324 15:54:09.843911 26181 solver.cpp:228] Iteration 450, loss = 0.336559
I0324 15:54:09.843940 26181 solver.cpp:244]     Train net output #0: loss = 0.336559 (* 1 = 0.336559 loss)
I0324 15:54:09.843951 26181 sgd_solver.cpp:106] Iteration 450, lr = 0.00967526
I0324 15:54:10.242599 26181 solver.cpp:228] Iteration 460, loss = 0.130235
I0324 15:54:10.242625 26181 solver.cpp:244]     Train net output #0: loss = 0.130235 (* 1 = 0.130235 loss)
I0324 15:54:10.242638 26181 sgd_solver.cpp:106] Iteration 460, lr = 0.00966833
I0324 15:54:10.641362 26181 solver.cpp:228] Iteration 470, loss = 0.175222
I0324 15:54:10.641429 26181 solver.cpp:244]     Train net output #0: loss = 0.175222 (* 1 = 0.175222 loss)
I0324 15:54:10.641443 26181 sgd_solver.cpp:106] Iteration 470, lr = 0.0096614
I0324 15:54:11.040293 26181 solver.cpp:228] Iteration 480, loss = 0.165948
I0324 15:54:11.040326 26181 solver.cpp:244]     Train net output #0: loss = 0.165948 (* 1 = 0.165948 loss)
I0324 15:54:11.040339 26181 sgd_solver.cpp:106] Iteration 480, lr = 0.00965448
I0324 15:54:11.438992 26181 solver.cpp:228] Iteration 490, loss = 0.201943
I0324 15:54:11.439019 26181 solver.cpp:244]     Train net output #0: loss = 0.201943 (* 1 = 0.201943 loss)
I0324 15:54:11.439033 26181 sgd_solver.cpp:106] Iteration 490, lr = 0.00964758
I0324 15:54:11.797965 26181 solver.cpp:337] Iteration 500, Testing net (#0)
I0324 15:54:16.094137 26181 solver.cpp:404]     Test net output #0: loss = 0.201622 (* 1 = 0.201622 loss)
I0324 15:54:16.124184 26181 solver.cpp:228] Iteration 500, loss = 0.244015
I0324 15:54:16.124212 26181 solver.cpp:244]     Train net output #0: loss = 0.244015 (* 1 = 0.244015 loss)
I0324 15:54:16.124228 26181 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0324 15:54:16.522903 26181 solver.cpp:228] Iteration 510, loss = 0.255855
I0324 15:54:16.522930 26181 solver.cpp:244]     Train net output #0: loss = 0.255855 (* 1 = 0.255855 loss)
I0324 15:54:16.522943 26181 sgd_solver.cpp:106] Iteration 510, lr = 0.00963381
I0324 15:54:16.921680 26181 solver.cpp:228] Iteration 520, loss = 0.327806
I0324 15:54:16.921707 26181 solver.cpp:244]     Train net output #0: loss = 0.327805 (* 1 = 0.327805 loss)
I0324 15:54:16.921720 26181 sgd_solver.cpp:106] Iteration 520, lr = 0.00962694
I0324 15:54:17.320531 26181 solver.cpp:228] Iteration 530, loss = 0.0788328
I0324 15:54:17.320559 26181 solver.cpp:244]     Train net output #0: loss = 0.0788327 (* 1 = 0.0788327 loss)
I0324 15:54:17.320572 26181 sgd_solver.cpp:106] Iteration 530, lr = 0.00962008
I0324 15:54:17.719346 26181 solver.cpp:228] Iteration 540, loss = 0.12329
I0324 15:54:17.719373 26181 solver.cpp:244]     Train net output #0: loss = 0.123289 (* 1 = 0.123289 loss)
I0324 15:54:17.719386 26181 sgd_solver.cpp:106] Iteration 540, lr = 0.00961323
I0324 15:54:18.118108 26181 solver.cpp:228] Iteration 550, loss = 0.27315
I0324 15:54:18.118136 26181 solver.cpp:244]     Train net output #0: loss = 0.27315 (* 1 = 0.27315 loss)
I0324 15:54:18.118149 26181 sgd_solver.cpp:106] Iteration 550, lr = 0.0096064
I0324 15:54:18.516870 26181 solver.cpp:228] Iteration 560, loss = 0.426758
I0324 15:54:18.516896 26181 solver.cpp:244]     Train net output #0: loss = 0.426758 (* 1 = 0.426758 loss)
I0324 15:54:18.516909 26181 sgd_solver.cpp:106] Iteration 560, lr = 0.00959958
I0324 15:54:18.915820 26181 solver.cpp:228] Iteration 570, loss = 0.112997
I0324 15:54:18.915858 26181 solver.cpp:244]     Train net output #0: loss = 0.112997 (* 1 = 0.112997 loss)
I0324 15:54:18.915870 26181 sgd_solver.cpp:106] Iteration 570, lr = 0.00959276
I0324 15:54:19.314535 26181 solver.cpp:228] Iteration 580, loss = 0.156255
I0324 15:54:19.314561 26181 solver.cpp:244]     Train net output #0: loss = 0.156254 (* 1 = 0.156254 loss)
I0324 15:54:19.314574 26181 sgd_solver.cpp:106] Iteration 580, lr = 0.00958596
I0324 15:54:19.713331 26181 solver.cpp:228] Iteration 590, loss = 0.107313
I0324 15:54:19.713358 26181 solver.cpp:244]     Train net output #0: loss = 0.107313 (* 1 = 0.107313 loss)
I0324 15:54:19.713371 26181 sgd_solver.cpp:106] Iteration 590, lr = 0.00957917
I0324 15:54:20.072350 26181 solver.cpp:337] Iteration 600, Testing net (#0)
I0324 15:54:24.369055 26181 solver.cpp:404]     Test net output #0: loss = 0.156194 (* 1 = 0.156194 loss)
I0324 15:54:24.399091 26181 solver.cpp:228] Iteration 600, loss = 0.209996
I0324 15:54:24.399116 26181 solver.cpp:244]     Train net output #0: loss = 0.209996 (* 1 = 0.209996 loss)
I0324 15:54:24.399132 26181 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0324 15:54:24.797826 26181 solver.cpp:228] Iteration 610, loss = 0.0262827
I0324 15:54:24.797852 26181 solver.cpp:244]     Train net output #0: loss = 0.0262826 (* 1 = 0.0262826 loss)
I0324 15:54:24.797904 26181 sgd_solver.cpp:106] Iteration 610, lr = 0.00956563
I0324 15:54:25.196595 26181 solver.cpp:228] Iteration 620, loss = 0.193661
I0324 15:54:25.196624 26181 solver.cpp:244]     Train net output #0: loss = 0.193661 (* 1 = 0.193661 loss)
I0324 15:54:25.196636 26181 sgd_solver.cpp:106] Iteration 620, lr = 0.00955887
I0324 15:54:25.595396 26181 solver.cpp:228] Iteration 630, loss = 0.103693
I0324 15:54:25.595423 26181 solver.cpp:244]     Train net output #0: loss = 0.103693 (* 1 = 0.103693 loss)
I0324 15:54:25.595437 26181 sgd_solver.cpp:106] Iteration 630, lr = 0.00955213
I0324 15:54:25.994115 26181 solver.cpp:228] Iteration 640, loss = 0.225098
I0324 15:54:25.994143 26181 solver.cpp:244]     Train net output #0: loss = 0.225098 (* 1 = 0.225098 loss)
I0324 15:54:25.994155 26181 sgd_solver.cpp:106] Iteration 640, lr = 0.00954539
I0324 15:54:26.392897 26181 solver.cpp:228] Iteration 650, loss = 0.205123
I0324 15:54:26.392925 26181 solver.cpp:244]     Train net output #0: loss = 0.205123 (* 1 = 0.205123 loss)
I0324 15:54:26.392937 26181 sgd_solver.cpp:106] Iteration 650, lr = 0.00953867
I0324 15:54:26.791832 26181 solver.cpp:228] Iteration 660, loss = 0.0710363
I0324 15:54:26.791860 26181 solver.cpp:244]     Train net output #0: loss = 0.0710362 (* 1 = 0.0710362 loss)
I0324 15:54:26.791873 26181 sgd_solver.cpp:106] Iteration 660, lr = 0.00953196
I0324 15:54:27.190582 26181 solver.cpp:228] Iteration 670, loss = 0.339899
I0324 15:54:27.190618 26181 solver.cpp:244]     Train net output #0: loss = 0.339899 (* 1 = 0.339899 loss)
I0324 15:54:27.190629 26181 sgd_solver.cpp:106] Iteration 670, lr = 0.00952526
I0324 15:54:27.589323 26181 solver.cpp:228] Iteration 680, loss = 0.273021
I0324 15:54:27.589350 26181 solver.cpp:244]     Train net output #0: loss = 0.273021 (* 1 = 0.273021 loss)
I0324 15:54:27.589362 26181 sgd_solver.cpp:106] Iteration 680, lr = 0.00951857
I0324 15:54:27.988162 26181 solver.cpp:228] Iteration 690, loss = 0.135365
I0324 15:54:27.988188 26181 solver.cpp:244]     Train net output #0: loss = 0.135365 (* 1 = 0.135365 loss)
I0324 15:54:27.988201 26181 sgd_solver.cpp:106] Iteration 690, lr = 0.00951189
I0324 15:54:28.347295 26181 solver.cpp:337] Iteration 700, Testing net (#0)
I0324 15:54:32.646420 26181 solver.cpp:404]     Test net output #0: loss = 0.168375 (* 1 = 0.168375 loss)
I0324 15:54:32.677636 26181 solver.cpp:228] Iteration 700, loss = 0.243747
I0324 15:54:32.677698 26181 solver.cpp:244]     Train net output #0: loss = 0.243747 (* 1 = 0.243747 loss)
I0324 15:54:32.677717 26181 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0324 15:54:33.076716 26181 solver.cpp:228] Iteration 710, loss = 0.297946
I0324 15:54:33.076769 26181 solver.cpp:244]     Train net output #0: loss = 0.297946 (* 1 = 0.297946 loss)
I0324 15:54:33.076783 26181 sgd_solver.cpp:106] Iteration 710, lr = 0.00949856
I0324 15:54:33.475847 26181 solver.cpp:228] Iteration 720, loss = 0.270177
I0324 15:54:33.475899 26181 solver.cpp:244]     Train net output #0: loss = 0.270177 (* 1 = 0.270177 loss)
I0324 15:54:33.475914 26181 sgd_solver.cpp:106] Iteration 720, lr = 0.00949192
I0324 15:54:33.874927 26181 solver.cpp:228] Iteration 730, loss = 0.36446
I0324 15:54:33.874982 26181 solver.cpp:244]     Train net output #0: loss = 0.36446 (* 1 = 0.36446 loss)
I0324 15:54:33.875000 26181 sgd_solver.cpp:106] Iteration 730, lr = 0.00948528
I0324 15:54:34.274343 26181 solver.cpp:228] Iteration 740, loss = 0.308822
I0324 15:54:34.274405 26181 solver.cpp:244]     Train net output #0: loss = 0.308822 (* 1 = 0.308822 loss)
I0324 15:54:34.274422 26181 sgd_solver.cpp:106] Iteration 740, lr = 0.00947866
I0324 15:54:34.673418 26181 solver.cpp:228] Iteration 750, loss = 0.168063
I0324 15:54:34.673499 26181 solver.cpp:244]     Train net output #0: loss = 0.168063 (* 1 = 0.168063 loss)
I0324 15:54:34.673512 26181 sgd_solver.cpp:106] Iteration 750, lr = 0.00947204
I0324 15:54:35.071424 26181 solver.cpp:228] Iteration 760, loss = 0.152879
I0324 15:54:35.071498 26181 solver.cpp:244]     Train net output #0: loss = 0.152879 (* 1 = 0.152879 loss)
I0324 15:54:35.071516 26181 sgd_solver.cpp:106] Iteration 760, lr = 0.00946544
I0324 15:54:35.469676 26181 solver.cpp:228] Iteration 770, loss = 0.075386
I0324 15:54:35.469749 26181 solver.cpp:244]     Train net output #0: loss = 0.075386 (* 1 = 0.075386 loss)
I0324 15:54:35.469766 26181 sgd_solver.cpp:106] Iteration 770, lr = 0.00945885
I0324 15:54:35.869325 26181 solver.cpp:228] Iteration 780, loss = 0.145935
I0324 15:54:35.869410 26181 solver.cpp:244]     Train net output #0: loss = 0.145935 (* 1 = 0.145935 loss)
I0324 15:54:35.869426 26181 sgd_solver.cpp:106] Iteration 780, lr = 0.00945227
I0324 15:54:36.268473 26181 solver.cpp:228] Iteration 790, loss = 0.130209
I0324 15:54:36.268550 26181 solver.cpp:244]     Train net output #0: loss = 0.130209 (* 1 = 0.130209 loss)
I0324 15:54:36.268565 26181 sgd_solver.cpp:106] Iteration 790, lr = 0.0094457
I0324 15:54:36.627826 26181 solver.cpp:337] Iteration 800, Testing net (#0)
I0324 15:54:40.926605 26181 solver.cpp:404]     Test net output #0: loss = 0.16096 (* 1 = 0.16096 loss)
I0324 15:54:40.957080 26181 solver.cpp:228] Iteration 800, loss = 0.252871
I0324 15:54:40.957115 26181 solver.cpp:244]     Train net output #0: loss = 0.252871 (* 1 = 0.252871 loss)
I0324 15:54:40.957144 26181 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0324 15:54:41.356631 26181 solver.cpp:228] Iteration 810, loss = 0.101357
I0324 15:54:41.356665 26181 solver.cpp:244]     Train net output #0: loss = 0.101357 (* 1 = 0.101357 loss)
I0324 15:54:41.356689 26181 sgd_solver.cpp:106] Iteration 810, lr = 0.00943258
I0324 15:54:41.755113 26181 solver.cpp:228] Iteration 820, loss = 0.0352949
I0324 15:54:41.755146 26181 solver.cpp:244]     Train net output #0: loss = 0.0352949 (* 1 = 0.0352949 loss)
I0324 15:54:41.755167 26181 sgd_solver.cpp:106] Iteration 820, lr = 0.00942605
I0324 15:54:42.153904 26181 solver.cpp:228] Iteration 830, loss = 0.279986
I0324 15:54:42.153937 26181 solver.cpp:244]     Train net output #0: loss = 0.279986 (* 1 = 0.279986 loss)
I0324 15:54:42.153959 26181 sgd_solver.cpp:106] Iteration 830, lr = 0.00941952
I0324 15:54:42.552667 26181 solver.cpp:228] Iteration 840, loss = 0.130054
I0324 15:54:42.552700 26181 solver.cpp:244]     Train net output #0: loss = 0.130054 (* 1 = 0.130054 loss)
I0324 15:54:42.552721 26181 sgd_solver.cpp:106] Iteration 840, lr = 0.009413
I0324 15:54:42.951479 26181 solver.cpp:228] Iteration 850, loss = 0.122428
I0324 15:54:42.951539 26181 solver.cpp:244]     Train net output #0: loss = 0.122428 (* 1 = 0.122428 loss)
I0324 15:54:42.951561 26181 sgd_solver.cpp:106] Iteration 850, lr = 0.00940649
I0324 15:54:43.350261 26181 solver.cpp:228] Iteration 860, loss = 0.0903965
I0324 15:54:43.350294 26181 solver.cpp:244]     Train net output #0: loss = 0.0903965 (* 1 = 0.0903965 loss)
I0324 15:54:43.350316 26181 sgd_solver.cpp:106] Iteration 860, lr = 0.0094
I0324 15:54:43.749017 26181 solver.cpp:228] Iteration 870, loss = 0.220289
I0324 15:54:43.749048 26181 solver.cpp:244]     Train net output #0: loss = 0.220289 (* 1 = 0.220289 loss)
I0324 15:54:43.749070 26181 sgd_solver.cpp:106] Iteration 870, lr = 0.00939351
I0324 15:54:44.147853 26181 solver.cpp:228] Iteration 880, loss = 0.205592
I0324 15:54:44.147886 26181 solver.cpp:244]     Train net output #0: loss = 0.205592 (* 1 = 0.205592 loss)
I0324 15:54:44.147908 26181 sgd_solver.cpp:106] Iteration 880, lr = 0.00938703
I0324 15:54:44.546564 26181 solver.cpp:228] Iteration 890, loss = 0.0700076
I0324 15:54:44.546597 26181 solver.cpp:244]     Train net output #0: loss = 0.0700075 (* 1 = 0.0700075 loss)
I0324 15:54:44.546618 26181 sgd_solver.cpp:106] Iteration 890, lr = 0.00938057
I0324 15:54:44.905578 26181 solver.cpp:337] Iteration 900, Testing net (#0)
I0324 15:54:49.201853 26181 solver.cpp:404]     Test net output #0: loss = 0.140766 (* 1 = 0.140766 loss)
I0324 15:54:49.231902 26181 solver.cpp:228] Iteration 900, loss = 0.220232
I0324 15:54:49.231933 26181 solver.cpp:244]     Train net output #0: loss = 0.220232 (* 1 = 0.220232 loss)
I0324 15:54:49.231958 26181 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0324 15:54:49.630601 26181 solver.cpp:228] Iteration 910, loss = 0.0382988
I0324 15:54:49.630635 26181 solver.cpp:244]     Train net output #0: loss = 0.0382987 (* 1 = 0.0382987 loss)
I0324 15:54:49.630656 26181 sgd_solver.cpp:106] Iteration 910, lr = 0.00936767
I0324 15:54:50.029356 26181 solver.cpp:228] Iteration 920, loss = 0.0222095
I0324 15:54:50.029388 26181 solver.cpp:244]     Train net output #0: loss = 0.0222094 (* 1 = 0.0222094 loss)
I0324 15:54:50.029410 26181 sgd_solver.cpp:106] Iteration 920, lr = 0.00936123
I0324 15:54:50.428140 26181 solver.cpp:228] Iteration 930, loss = 0.0271392
I0324 15:54:50.428174 26181 solver.cpp:244]     Train net output #0: loss = 0.0271392 (* 1 = 0.0271392 loss)
I0324 15:54:50.428195 26181 sgd_solver.cpp:106] Iteration 930, lr = 0.00935481
I0324 15:54:50.826835 26181 solver.cpp:228] Iteration 940, loss = 0.204996
I0324 15:54:50.826869 26181 solver.cpp:244]     Train net output #0: loss = 0.204996 (* 1 = 0.204996 loss)
I0324 15:54:50.826889 26181 sgd_solver.cpp:106] Iteration 940, lr = 0.00934839
I0324 15:54:51.225556 26181 solver.cpp:228] Iteration 950, loss = 0.185848
I0324 15:54:51.225590 26181 solver.cpp:244]     Train net output #0: loss = 0.185848 (* 1 = 0.185848 loss)
I0324 15:54:51.225611 26181 sgd_solver.cpp:106] Iteration 950, lr = 0.00934199
I0324 15:54:51.624349 26181 solver.cpp:228] Iteration 960, loss = 0.0708883
I0324 15:54:51.624382 26181 solver.cpp:244]     Train net output #0: loss = 0.0708882 (* 1 = 0.0708882 loss)
I0324 15:54:51.624402 26181 sgd_solver.cpp:106] Iteration 960, lr = 0.0093356
I0324 15:54:52.023113 26181 solver.cpp:228] Iteration 970, loss = 0.101661
I0324 15:54:52.023144 26181 solver.cpp:244]     Train net output #0: loss = 0.101661 (* 1 = 0.101661 loss)
I0324 15:54:52.023164 26181 sgd_solver.cpp:106] Iteration 970, lr = 0.00932921
I0324 15:54:52.421901 26181 solver.cpp:228] Iteration 980, loss = 0.361706
I0324 15:54:52.421933 26181 solver.cpp:244]     Train net output #0: loss = 0.361706 (* 1 = 0.361706 loss)
I0324 15:54:52.421955 26181 sgd_solver.cpp:106] Iteration 980, lr = 0.00932284
I0324 15:54:52.820755 26181 solver.cpp:228] Iteration 990, loss = 0.151651
I0324 15:54:52.820787 26181 solver.cpp:244]     Train net output #0: loss = 0.151651 (* 1 = 0.151651 loss)
I0324 15:54:52.820808 26181 sgd_solver.cpp:106] Iteration 990, lr = 0.00931648
I0324 15:54:53.179774 26181 solver.cpp:454] Snapshotting to binary proto file _iter_1000.caffemodel
I0324 15:54:53.200618 26181 sgd_solver.cpp:273] Snapshotting solver state to binary proto file _iter_1000.solverstate
I0324 15:54:53.233511 26181 solver.cpp:317] Iteration 1000, loss = 0.190021
I0324 15:54:53.233547 26181 solver.cpp:337] Iteration 1000, Testing net (#0)
I0324 15:54:57.521090 26181 solver.cpp:404]     Test net output #0: loss = 0.135575 (* 1 = 0.135575 loss)
I0324 15:54:57.521131 26181 solver.cpp:322] Optimization Done.
I0324 15:54:57.521143 26181 caffe.cpp:222] Optimization Done.
